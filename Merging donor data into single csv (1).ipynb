{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f01fa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26d5adef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Karachi monthly data: (68, 4)\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# 1. Load Karachi MONTHLY data (you already generated)\n",
    "# ======================================================\n",
    "\n",
    "karachi_file = \"karachi_monthly_pm25.csv\"  \n",
    "karachi = pd.read_csv(karachi_file)\n",
    "\n",
    "# Standardize\n",
    "karachi[\"date\"] = pd.to_datetime(karachi[\"YearMonth\"])\n",
    "karachi[\"pm25\"] = karachi[\"Raw Conc.\"]\n",
    "karachi[\"country\"] = \"Pakistan\"\n",
    "karachi[\"city\"] = \"Karachi\"\n",
    "karachi = karachi[[\"country\",\"city\",\"date\",\"pm25\"]]\n",
    "\n",
    "print(\"Loaded Karachi monthly data:\", karachi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7eee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 1. Load Karachi MONTHLY data (you already generated)\n",
    "# ======================================================\n",
    "\n",
    "karachi_file = \"karachi_dhaphas_monthly_pm25.csv\"  \n",
    "karachi = pd.read_csv(karachi_file)\n",
    "\n",
    "# Standardize\n",
    "karachi[\"date\"] = pd.to_datetime(karachi[\"date\"])\n",
    "karachi[\"country\"] = \"Pakistan\"\n",
    "karachi[\"city\"] = \"Karachi\"\n",
    "karachi = karachi[[\"country\",\"city\",\"date\",\"pm25\"]]\n",
    "\n",
    "print(\"Loaded Karachi monthly data:\", karachi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecd44685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found donor files: 18\n",
      "Processing: pm25_donors\\Dhaka_PM2.5_2016_YTD.csv\n",
      "Processing: pm25_donors\\Dhaka_PM2.5_2017_YTD.csv\n",
      "Processing: pm25_donors\\Dhaka_PM2.5_2018_YTD.csv\n",
      "Processing: pm25_donors\\Dhaka_PM2.5_2019_YTD.csv\n",
      "Processing: pm25_donors\\Dhaka_PM2.5_2020_YTD.csv\n",
      "Processing: pm25_donors\\Dhaka_PM2.5_2021_YTD.csv\n",
      "Processing: pm25_donors\\Dhaka_PM2.5_2022_YTD.csv\n",
      "Processing: pm25_donors\\Dhaka_PM2.5_2023_YTD.csv\n",
      "Processing: pm25_donors\\Dushanbe_PM2.5_2019_YTD.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jinho Kim\\AppData\\Local\\Temp\\ipykernel_29108\\832173828.py:35: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"date\"] = pd.to_datetime(df[\"Date (LT)\"], errors=\"coerce\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: pm25_donors\\Dushanbe_PM2.5_2020_YTD.csv\n",
      "Processing: pm25_donors\\Dushanbe_PM2.5_2021_YTD.csv\n",
      "Processing: pm25_donors\\Dushanbe_PM2.5_2022_YTD.csv\n",
      "Processing: pm25_donors\\Dushanbe_PM2.5_2023_YTD.csv\n",
      "Processing: pm25_donors\\Rangoon_PM2.5_2019_YTD.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jinho Kim\\AppData\\Local\\Temp\\ipykernel_29108\\832173828.py:35: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"date\"] = pd.to_datetime(df[\"Date (LT)\"], errors=\"coerce\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: pm25_donors\\Rangoon_PM2.5_2020_YTD.csv\n",
      "Processing: pm25_donors\\Rangoon_PM2.5_2021_YTD.csv\n",
      "Processing: pm25_donors\\Rangoon_PM2.5_2022_YTD.csv\n",
      "Processing: pm25_donors\\Rangoon_PM2.5_2023_YTD.csv\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# 2. Load ALL donor files (hourly PM2.5)\n",
    "# ======================================================\n",
    "\n",
    "donor_folder = \"pm25_donors/*.csv\"  # <-- CHANGE PATH\n",
    "files = glob(donor_folder)\n",
    "\n",
    "print(\"Found donor files:\", len(files))\n",
    "\n",
    "all_monthly_donors = []\n",
    "\n",
    "# Mapping from city names found in filenames → country\n",
    "city_to_country = {\n",
    "    \"Dhaka\": \"Bangladesh\",\n",
    "    \"Dushanbe\": \"Tajikistan\",\n",
    "    \"Rangoon\": \"Myanmar\",\n",
    "    #\"Baghdad\": \"Iraq\",\n",
    "    #\"Dhahran\": \"SaudiArabia\"\n",
    "    #\"Jeddah\": \"SaudiArabia\"\n",
    "}\n",
    "\n",
    "for f in files:\n",
    "    print(f\"Processing:\", f)\n",
    "\n",
    "    df = pd.read_csv(f)\n",
    "\n",
    "    # --- Standardize column names (but keep original capitalization for safety) ---\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    # Check required columns exist\n",
    "    if \"Date (LT)\" not in df.columns or \"Raw Conc.\" not in df.columns:\n",
    "        raise ValueError(f\"Unexpected donor file format: {f}\")\n",
    "\n",
    "    # --- Parse datetime ---\n",
    "    df[\"date\"] = pd.to_datetime(df[\"Date (LT)\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"date\"])\n",
    "\n",
    "    # --- Extract PM2.5 ---\n",
    "    df[\"pm25\"] = pd.to_numeric(df[\"Raw Conc.\"], errors=\"coerce\")\n",
    "    # Clean invalid PM2.5 values\n",
    "    df.loc[df[\"pm25\"] < 0, \"pm25\"] = np.nan      # remove -999 etc.\n",
    "    df.loc[df[\"pm25\"] > 1000, \"pm25\"] = np.nan   # remove sensor overflow\n",
    "    df = df.dropna(subset=[\"pm25\"])\n",
    "\n",
    "    # --- Optional: keep only valid QC ---\n",
    "    # df = df[df[\"QC Name\"] == \"Valid\"]\n",
    "\n",
    "    # --- Identify city from filename ---\n",
    "    filename = os.path.basename(f)          # Works on Windows/macOS/Linux\n",
    "    name_no_ext = filename.replace(\".csv\", \"\")\n",
    "\n",
    "    # Example filenames:\n",
    "    #   Baghdad_PM2.5_2019_YTD.csv\n",
    "    #   Dhaka_PM2.5_2017.csv\n",
    "    # So split by \"_\" and take the first piece:\n",
    "    city_guess = name_no_ext.split(\"_\")[0]\n",
    "\n",
    "    if city_guess not in city_to_country:\n",
    "        raise ValueError(f\"City not recognized: '{city_guess}' extracted from '{filename}'\")\n",
    "\n",
    "    country = city_to_country[city_guess]\n",
    "\n",
    "    # --- Compute MONTHLY average ---\n",
    "    df[\"year_month\"] = df[\"date\"].dt.to_period(\"M\")\n",
    "    monthly = df.groupby(\"year_month\")[\"pm25\"].mean().reset_index()\n",
    "    monthly[\"date\"] = monthly[\"year_month\"].dt.to_timestamp()\n",
    "\n",
    "    # Add city & country\n",
    "    monthly[\"city\"] = city_guess\n",
    "    monthly[\"country\"] = country\n",
    "\n",
    "    monthly = monthly[[\"country\",\"city\",\"date\",\"pm25\"]]\n",
    "\n",
    "    all_monthly_donors.append(monthly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7faab362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donor monthly dataset shape: (223, 4)\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# 3. Combine ALL donors\n",
    "# ======================================================\n",
    "\n",
    "donors = pd.concat(all_monthly_donors, ignore_index=True)\n",
    "print(\"Donor monthly dataset shape:\", donors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8a10e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved merged dataset to pm25_panel.csv\n",
      "       country   city       date        pm25\n",
      "68  Bangladesh  Dhaka 2016-03-01  108.788410\n",
      "69  Bangladesh  Dhaka 2016-04-01   49.787204\n",
      "70  Bangladesh  Dhaka 2016-05-01   51.318548\n",
      "71  Bangladesh  Dhaka 2016-06-01   39.015406\n",
      "72  Bangladesh  Dhaka 2016-07-01   29.364738\n",
      "        country      city       date       pm25\n",
      "225  Tajikistan  Dushanbe 2023-09-01  63.004918\n",
      "226  Tajikistan  Dushanbe 2023-10-01  43.313669\n",
      "227  Tajikistan  Dushanbe 2023-11-01  46.177778\n",
      "228  Tajikistan  Dushanbe 2023-12-01  79.358008\n",
      "229  Tajikistan  Dushanbe 2024-01-01  36.000000\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# 4. Combine Karachi + Donors → FINAL PANEL\n",
    "# ======================================================\n",
    "\n",
    "panel = pd.concat([karachi, donors], ignore_index=True)\n",
    "\n",
    "panel = panel.sort_values([\"country\",\"city\",\"date\"])\n",
    "panel.to_csv(\"pm25_panel.csv\", index=False)\n",
    "\n",
    "print(\"\\nSaved merged dataset to pm25_panel.csv\")\n",
    "print(panel.head())\n",
    "print(panel.tail())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
